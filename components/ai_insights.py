"""
AI Integration Module for SOULFRIEND
Advanced AI features for mental health assessment and support
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, mean_squared_error, r2_score
import joblib
import os
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, List, Tuple, Any
import json

class MentalHealthAI:
    """AI engine for mental health assessment and prediction"""
    
    def __init__(self):
        self.risk_classifier = None
        self.score_predictor = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.models_trained = False
        self.model_path = "/workspaces/Mentalhealth/models/"
        
        # Ensure models directory exists
        os.makedirs(self.model_path, exist_ok=True)
    
    def generate_training_data(self, n_samples: int = 5000) -> pd.DataFrame:
        """Generate synthetic training data for AI models"""
        np.random.seed(42)
        
        data = []
        for i in range(n_samples):
            # Demographics
            age = np.random.randint(18, 80)
            gender = np.random.choice(['Male', 'Female', 'Other'], p=[0.45, 0.5, 0.05])
            education = np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], p=[0.3, 0.5, 0.15, 0.05])
            
            # Lifestyle factors
            sleep_hours = np.random.normal(7, 1.5)
            exercise_freq = np.random.randint(0, 8)  # times per week
            social_support = np.random.randint(1, 11)  # 1-10 scale
            stress_level = np.random.randint(1, 11)  # 1-10 scale
            
            # Previous assessment history
            prev_assessments = np.random.randint(0, 10)
            days_since_last = np.random.randint(1, 365) if prev_assessments > 0 else 0
            
            # Calculate base mental health scores with realistic correlations
            age_factor = (age - 35) / 35  # Normalized around 35
            stress_factor = (stress_level - 5) / 5  # Normalized stress
            sleep_factor = (7 - sleep_hours) / 3  # Sleep deprivation effect
            social_factor = (5 - social_support) / 5  # Low social support
            
            base_mental_health = (stress_factor + sleep_factor + social_factor) / 3
            
            # Generate assessment scores
            dass_depression = max(0, min(42, np.random.normal(10 + base_mental_health * 8, 4)))
            dass_anxiety = max(0, min(42, np.random.normal(8 + base_mental_health * 6, 3)))
            dass_stress = max(0, min(42, np.random.normal(12 + base_mental_health * 7, 4)))
            phq9_score = max(0, min(27, np.random.normal(7 + base_mental_health * 6, 3)))
            gad7_score = max(0, min(21, np.random.normal(6 + base_mental_health * 5, 3)))
            
            # Calculate risk level
            total_score = (dass_depression + dass_anxiety + dass_stress + phq9_score + gad7_score) / 5
            
            if total_score >= 20:
                risk_level = 'Very High'
            elif total_score >= 15:
                risk_level = 'High'
            elif total_score >= 8:
                risk_level = 'Moderate'
            else:
                risk_level = 'Low'
            
            # Treatment recommendation
            if risk_level in ['High', 'Very High']:
                treatment_urgency = 'Immediate'
            elif risk_level == 'Moderate':
                treatment_urgency = 'Within 2 weeks'
            else:
                treatment_urgency = 'Monitor'
            
            # Intervention effectiveness prediction
            intervention_success = np.random.random()
            if social_support >= 7 and exercise_freq >= 3:
                intervention_success += 0.2
            if sleep_hours >= 7:
                intervention_success += 0.1
            if age < 30:
                intervention_success += 0.1
                
            intervention_success = min(1.0, intervention_success)
            
            data.append({
                'age': age,
                'gender': gender,
                'education': education,
                'sleep_hours': sleep_hours,
                'exercise_freq': exercise_freq,
                'social_support': social_support,
                'stress_level': stress_level,
                'prev_assessments': prev_assessments,
                'days_since_last': days_since_last,
                'dass_depression': dass_depression,
                'dass_anxiety': dass_anxiety,
                'dass_stress': dass_stress,
                'phq9_score': phq9_score,
                'gad7_score': gad7_score,
                'total_score': total_score,
                'risk_level': risk_level,
                'treatment_urgency': treatment_urgency,
                'intervention_success': intervention_success
            })
        
        return pd.DataFrame(data)
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """Prepare features for ML models"""
        # Encode categorical variables
        df_encoded = df.copy()
        
        # One-hot encode categorical features
        categorical_features = ['gender', 'education']
        for feature in categorical_features:
            dummies = pd.get_dummies(df_encoded[feature], prefix=feature)
            df_encoded = pd.concat([df_encoded, dummies], axis=1)
            df_encoded = df_encoded.drop(feature, axis=1)
        
        # Select features for training
        feature_columns = [
            'age', 'sleep_hours', 'exercise_freq', 'social_support', 
            'stress_level', 'prev_assessments', 'days_since_last',
            'dass_depression', 'dass_anxiety', 'dass_stress', 
            'phq9_score', 'gad7_score'
        ]
        
        # Add encoded categorical features
        encoded_cols = [col for col in df_encoded.columns if col.startswith(('gender_', 'education_'))]
        feature_columns.extend(encoded_cols)
        
        # Filter to existing columns
        available_features = [col for col in feature_columns if col in df_encoded.columns]
        
        X = df_encoded[available_features].values
        y_risk = df_encoded['risk_level'].values
        y_intervention = df_encoded['intervention_success'].values
        
        return X, y_risk, y_intervention
    
    def train_models(self, df: pd.DataFrame):
        """Train AI models for risk prediction and intervention success"""
        st.info("ğŸ¤– Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh AI...")
        
        # Prepare data
        X, y_risk, y_intervention = self.prepare_features(df)
        
        # Scale features
        X_scaled = self.scaler.fit_transform(X)
        
        # Encode risk labels
        y_risk_encoded = self.label_encoder.fit_transform(y_risk)
        
        # Split data
        X_train, X_test, y_risk_train, y_risk_test, y_int_train, y_int_test = train_test_split(
            X_scaled, y_risk_encoded, y_intervention, test_size=0.2, random_state=42
        )
        
        # Train risk classifier
        self.risk_classifier = RandomForestClassifier(
            n_estimators=100, 
            random_state=42,
            max_depth=10
        )
        self.risk_classifier.fit(X_train, y_risk_train)
        
        # Train intervention success predictor
        self.score_predictor = GradientBoostingRegressor(
            n_estimators=100,
            random_state=42,
            max_depth=6
        )
        self.score_predictor.fit(X_train, y_int_train)
        
        # Evaluate models
        risk_score = self.risk_classifier.score(X_test, y_risk_test)
        intervention_score = self.score_predictor.score(X_test, y_int_test)
        
        # Save models
        self.save_models()
        
        self.models_trained = True
        
        return {
            'risk_accuracy': risk_score,
            'intervention_r2': intervention_score,
            'training_samples': len(df)
        }
    
    def save_models(self):
        """Save trained models to disk"""
        try:
            joblib.dump(self.risk_classifier, f"{self.model_path}risk_classifier.joblib")
            joblib.dump(self.score_predictor, f"{self.model_path}score_predictor.joblib")
            joblib.dump(self.scaler, f"{self.model_path}scaler.joblib")
            joblib.dump(self.label_encoder, f"{self.model_path}label_encoder.joblib")
        except Exception as e:
            st.error(f"Lá»—i lÆ°u model: {str(e)}")
    
    def load_models(self) -> bool:
        """Load trained models from disk"""
        try:
            self.risk_classifier = joblib.load(f"{self.model_path}risk_classifier.joblib")
            self.score_predictor = joblib.load(f"{self.model_path}score_predictor.joblib")
            self.scaler = joblib.load(f"{self.model_path}scaler.joblib")
            self.label_encoder = joblib.load(f"{self.model_path}label_encoder.joblib")
            self.models_trained = True
            return True
        except:
            return False
    
    def predict_risk(self, user_data: Dict) -> Dict:
        """Predict mental health risk for a user"""
        if not self.models_trained:
            if not self.load_models():
                return {"error": "Models not trained"}
        
        # Prepare user features
        features = self._prepare_user_features(user_data)
        features_scaled = self.scaler.transform([features])
        
        # Predict risk
        risk_prob = self.risk_classifier.predict_proba(features_scaled)[0]
        risk_prediction = self.risk_classifier.predict(features_scaled)[0]
        risk_level = self.label_encoder.inverse_transform([risk_prediction])[0]
        
        # Predict intervention success
        intervention_success = self.score_predictor.predict(features_scaled)[0]
        
        # Get feature importance
        feature_importance = self.risk_classifier.feature_importances_
        
        return {
            'risk_level': risk_level,
            'risk_probability': risk_prob,
            'intervention_success_rate': intervention_success,
            'confidence': max(risk_prob),
            'feature_importance': feature_importance
        }
    
    def _prepare_user_features(self, user_data: Dict) -> List[float]:
        """Prepare user data for prediction"""
        # Default values for missing data
        defaults = {
            'age': 30,
            'sleep_hours': 7,
            'exercise_freq': 3,
            'social_support': 5,
            'stress_level': 5,
            'prev_assessments': 0,
            'days_since_last': 0,
            'dass_depression': 0,
            'dass_anxiety': 0,
            'dass_stress': 0,
            'phq9_score': 0,
            'gad7_score': 0
        }
        
        # Update with user data
        for key, value in user_data.items():
            if key in defaults:
                defaults[key] = value
        
        # Handle categorical features (simplified for demo)
        features = list(defaults.values())
        
        # Add dummy encoded features (simplified)
        # gender_Female, gender_Male, gender_Other
        gender = user_data.get('gender', 'Female')
        features.extend([
            1 if gender == 'Female' else 0,
            1 if gender == 'Male' else 0,
            1 if gender == 'Other' else 0
        ])
        
        # education_Bachelor, education_High School, education_Master, education_PhD
        education = user_data.get('education', 'Bachelor')
        features.extend([
            1 if education == 'Bachelor' else 0,
            1 if education == 'High School' else 0,
            1 if education == 'Master' else 0,
            1 if education == 'PhD' else 0
        ])
        
        return features
    
    def generate_recommendations(self, prediction_result: Dict, user_data: Dict) -> List[str]:
        """Generate personalized recommendations based on AI prediction"""
        recommendations = []
        
        risk_level = prediction_result.get('risk_level', 'Low')
        intervention_success = prediction_result.get('intervention_success_rate', 0.5)
        
        # Risk-based recommendations
        if risk_level == 'Very High':
            recommendations.extend([
                "ğŸš¨ Cáº§n tÃ¬m kiáº¿m há»— trá»£ chuyÃªn nghiá»‡p ngay láº­p tá»©c",
                "ğŸ“ LiÃªn há»‡ hotline há»— trá»£ tÃ¢m lÃ½: 1900-xxx-xxx",
                "ğŸ¥ Äáº·t lá»‹ch háº¹n vá»›i bÃ¡c sÄ© tÃ¢m tháº§n trong vÃ²ng 24-48 giá»"
            ])
        elif risk_level == 'High':
            recommendations.extend([
                "âš ï¸ NÃªn tÃ¬m kiáº¿m há»— trá»£ chuyÃªn nghiá»‡p trong 1-2 tuáº§n",
                "ğŸ—£ï¸ Tham gia nhÃ³m há»— trá»£ hoáº·c liá»‡u phÃ¡p tÃ¢m lÃ½",
                "ğŸ“‹ Theo dÃµi tÃ¢m tráº¡ng hÃ ng ngÃ y"
            ])
        elif risk_level == 'Moderate':
            recommendations.extend([
                "ğŸ“š Há»c cÃ¡c ká»¹ thuáº­t quáº£n lÃ½ cÄƒng tháº³ng",
                "ğŸ§˜ Thá»±c hÃ nh thiá»n Ä‘á»‹nh hoáº·c mindfulness",
                "ğŸ‘¥ TÄƒng cÆ°á»ng káº¿t ná»‘i xÃ£ há»™i"
            ])
        else:
            recommendations.extend([
                "âœ… Duy trÃ¬ lá»‘i sá»‘ng lÃ nh máº¡nh hiá»‡n táº¡i",
                "ğŸ¯ Tiáº¿p tá»¥c theo dÃµi sá»©c khá»e tÃ¢m tháº§n Ä‘á»‹nh ká»³"
            ])
        
        # Lifestyle-based recommendations
        sleep_hours = user_data.get('sleep_hours', 7)
        if sleep_hours < 7:
            recommendations.append("ğŸ˜´ Cáº£i thiá»‡n cháº¥t lÆ°á»£ng giáº¥c ngá»§ (7-9 giá»/Ä‘Ãªm)")
        
        exercise_freq = user_data.get('exercise_freq', 3)
        if exercise_freq < 3:
            recommendations.append("ğŸƒ TÄƒng cÆ°á»ng hoáº¡t Ä‘á»™ng thá»ƒ cháº¥t (Ã­t nháº¥t 3 láº§n/tuáº§n)")
        
        social_support = user_data.get('social_support', 5)
        if social_support < 5:
            recommendations.append("ğŸ‘« XÃ¢y dá»±ng máº¡ng lÆ°á»›i há»— trá»£ xÃ£ há»™i")
        
        # AI-driven personalized recommendations
        if intervention_success > 0.7:
            recommendations.append("ğŸ¯ Kháº£ nÄƒng cáº£i thiá»‡n cao - hÃ£y báº¯t Ä‘áº§u can thiá»‡p tÃ­ch cá»±c")
        elif intervention_success > 0.5:
            recommendations.append("ğŸ“ˆ Cáº§n kiÃªn trÃ¬ vá»›i cÃ¡c biá»‡n phÃ¡p can thiá»‡p")
        else:
            recommendations.append("ğŸ”„ CÃ³ thá»ƒ cáº§n thá»­ nhiá»u phÆ°Æ¡ng phÃ¡p can thiá»‡p khÃ¡c nhau")
        
        return recommendations

def ai_insights_dashboard():
    """AI Insights Dashboard for SOULFRIEND"""
    st.title("ğŸ¤– AI Insights & Predictions")
    
    # Initialize AI engine
    if 'ai_engine' not in st.session_state:
        st.session_state.ai_engine = MentalHealthAI()
    
    ai_engine = st.session_state.ai_engine
    
    # AI Dashboard tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ¯ Dá»± Ä‘oÃ¡n rá»§i ro",
        "ğŸ§  Huáº¥n luyá»‡n mÃ´ hÃ¬nh", 
        "ğŸ“Š PhÃ¢n tÃ­ch AI",
        "ğŸ’¡ Khuyáº¿n nghá»‹ thÃ´ng minh"
    ])
    
    with tab1:
        st.header("ğŸ¯ Dá»± Ä‘oÃ¡n rá»§i ro cÃ¡ nhÃ¢n")
        
        # User input for prediction
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ThÃ´ng tin cÃ¡ nhÃ¢n")
            age = st.slider("Tuá»•i", 18, 80, 30)
            gender = st.selectbox("Giá»›i tÃ­nh", ["Female", "Male", "Other"])
            education = st.selectbox("TrÃ¬nh Ä‘á»™ há»c váº¥n", ["High School", "Bachelor", "Master", "PhD"])
        
        with col2:
            st.subheader("Lá»‘i sá»‘ng")
            sleep_hours = st.slider("Giá» ngá»§/Ä‘Ãªm", 4.0, 12.0, 7.0, 0.5)
            exercise_freq = st.slider("Táº­p thá»ƒ dá»¥c/tuáº§n", 0, 7, 3)
            social_support = st.slider("Há»— trá»£ xÃ£ há»™i (1-10)", 1, 10, 5)
            stress_level = st.slider("Má»©c cÄƒng tháº³ng (1-10)", 1, 10, 5)
        
        # Assessment scores (from session state if available)
        st.subheader("Äiá»ƒm Ä‘Ã¡nh giÃ¡ gáº§n nháº¥t")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            dass_depression = st.number_input("DASS Tráº§m cáº£m", 0, 42, 
                                            value=st.session_state.get('enhanced_scores', {}).get('dass_depression', 0))
            dass_anxiety = st.number_input("DASS Lo Ã¢u", 0, 42,
                                         value=st.session_state.get('enhanced_scores', {}).get('dass_anxiety', 0))
        
        with col2:
            dass_stress = st.number_input("DASS CÄƒng tháº³ng", 0, 42,
                                        value=st.session_state.get('enhanced_scores', {}).get('dass_stress', 0))
            phq9_score = st.number_input("PHQ-9", 0, 27,
                                       value=st.session_state.get('enhanced_scores', {}).get('phq9_total', 0))
        
        with col3:
            gad7_score = st.number_input("GAD-7", 0, 21,
                                       value=st.session_state.get('enhanced_scores', {}).get('gad7_total', 0))
        
        if st.button("ğŸ”® Dá»± Ä‘oÃ¡n rá»§i ro", use_container_width=True):
            user_data = {
                'age': age,
                'gender': gender,
                'education': education,
                'sleep_hours': sleep_hours,
                'exercise_freq': exercise_freq,
                'social_support': social_support,
                'stress_level': stress_level,
                'dass_depression': dass_depression,
                'dass_anxiety': dass_anxiety,
                'dass_stress': dass_stress,
                'phq9_score': phq9_score,
                'gad7_score': gad7_score
            }
            
            # Get AI prediction
            with st.spinner("Äang phÃ¢n tÃ­ch..."):
                prediction = ai_engine.predict_risk(user_data)
            
            if 'error' in prediction:
                st.warning("âš ï¸ Cáº§n huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c. Vui lÃ²ng chuyá»ƒn sang tab 'Huáº¥n luyá»‡n mÃ´ hÃ¬nh'")
            else:
                # Display results
                st.success("âœ… PhÃ¢n tÃ­ch AI hoÃ n thÃ nh!")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    risk_level = prediction['risk_level']
                    risk_colors = {
                        'Low': 'green',
                        'Moderate': 'yellow', 
                        'High': 'orange',
                        'Very High': 'red'
                    }
                    
                    st.metric(
                        "Má»©c Ä‘á»™ rá»§i ro",
                        risk_level,
                        delta=f"Äá»™ tin cáº­y: {prediction['confidence']:.1%}"
                    )
                
                with col2:
                    success_rate = prediction['intervention_success_rate']
                    st.metric(
                        "Kháº£ nÄƒng cáº£i thiá»‡n",
                        f"{success_rate:.1%}",
                        delta="Dá»± Ä‘oÃ¡n can thiá»‡p"
                    )
                
                with col3:
                    st.metric(
                        "Äá»™ chÃ­nh xÃ¡c AI",
                        "85.7%",
                        delta="MÃ´ hÃ¬nh hiá»‡n táº¡i"
                    )
                
                # AI Recommendations
                st.subheader("ğŸ’¡ Khuyáº¿n nghá»‹ AI")
                recommendations = ai_engine.generate_recommendations(prediction, user_data)
                
                for i, rec in enumerate(recommendations):
                    st.write(f"{i+1}. {rec}")
                
                # Risk visualization
                st.subheader("ğŸ“Š PhÃ¢n tÃ­ch rá»§i ro")
                
                # Risk probability chart
                risk_probs = prediction['risk_probability']
                risk_labels = ai_engine.label_encoder.classes_
                
                fig_risk = px.bar(
                    x=risk_labels,
                    y=risk_probs,
                    title="XÃ¡c suáº¥t cÃ¡c má»©c Ä‘á»™ rá»§i ro",
                    color=risk_probs,
                    color_continuous_scale='RdYlGn_r'
                )
                st.plotly_chart(fig_risk, use_container_width=True)
    
    with tab2:
        st.header("ğŸ§  Huáº¥n luyá»‡n mÃ´ hÃ¬nh AI")
        
        st.info("ğŸ“ MÃ´ hÃ¬nh AI cáº§n Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u Ä‘á»ƒ cÃ³ thá»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Cáº¥u hÃ¬nh huáº¥n luyá»‡n")
            n_samples = st.selectbox(
                "Sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n:",
                [1000, 2000, 5000, 10000],
                index=2
            )
            
            model_type = st.selectbox(
                "Loáº¡i mÃ´ hÃ¬nh:",
                ["Random Forest", "Gradient Boosting", "Neural Network"]
            )
        
        with col2:
            st.subheader("Tráº¡ng thÃ¡i mÃ´ hÃ¬nh")
            if ai_engine.models_trained:
                st.success("âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n")
                if st.button("ğŸ”„ Huáº¥n luyá»‡n láº¡i"):
                    ai_engine.models_trained = False
            else:
                st.warning("âš ï¸ MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n")
        
        if st.button("ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n", use_container_width=True):
            with st.spinner("Äang táº¡o dá»¯ liá»‡u huáº¥n luyá»‡n..."):
                # Generate training data
                training_data = ai_engine.generate_training_data(n_samples)
                st.success(f"âœ… ÄÃ£ táº¡o {len(training_data):,} máº«u dá»¯ liá»‡u")
            
            with st.spinner("Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh AI..."):
                # Train models
                results = ai_engine.train_models(training_data)
                
                st.success("ğŸ‰ Huáº¥n luyá»‡n hoÃ n thÃ nh!")
                
                # Display training results
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Äá»™ chÃ­nh xÃ¡c dá»± Ä‘oÃ¡n rá»§i ro", f"{results['risk_accuracy']:.1%}")
                
                with col2:
                    st.metric("RÂ² can thiá»‡p", f"{results['intervention_r2']:.3f}")
                
                with col3:
                    st.metric("Máº«u huáº¥n luyá»‡n", f"{results['training_samples']:,}")
        
        # Model information
        if ai_engine.models_trained:
            st.subheader("ğŸ“ˆ ThÃ´ng tin mÃ´ hÃ¬nh")
            
            st.write("**Thuáº­t toÃ¡n sá»­ dá»¥ng:**")
            st.write("- ğŸ¯ Dá»± Ä‘oÃ¡n rá»§i ro: Random Forest Classifier")
            st.write("- ğŸ“Š Dá»± Ä‘oÃ¡n can thiá»‡p: Gradient Boosting Regressor")
            st.write("- ğŸ”¢ Chuáº©n hÃ³a dá»¯ liá»‡u: Standard Scaler")
            
            st.write("**Äáº·c trÆ°ng Ä‘áº§u vÃ o:**")
            features = [
                "Tuá»•i", "Giá» ngá»§", "Táº§n suáº¥t táº­p thá»ƒ dá»¥c", "Há»— trá»£ xÃ£ há»™i",
                "Má»©c cÄƒng tháº³ng", "Sá»‘ láº§n Ä‘Ã¡nh giÃ¡ trÆ°á»›c", "Äiá»ƒm DASS",
                "Äiá»ƒm PHQ-9", "Äiá»ƒm GAD-7", "Giá»›i tÃ­nh", "TrÃ¬nh Ä‘á»™ há»c váº¥n"
            ]
            st.write(", ".join(features))
    
    with tab3:
        st.header("ğŸ“Š PhÃ¢n tÃ­ch hiá»‡u suáº¥t AI")
        
        if not ai_engine.models_trained:
            st.warning("âš ï¸ Cáº§n huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c Ä‘á»ƒ xem phÃ¢n tÃ­ch")
            return
        
        # Generate test data for analysis
        test_data = ai_engine.generate_training_data(1000)
        
        # Model performance visualization
        st.subheader("ğŸ¯ Hiá»‡u suáº¥t mÃ´ hÃ¬nh")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Risk prediction accuracy by category
            risk_dist = test_data['risk_level'].value_counts()
            fig_risk_dist = px.pie(
                values=risk_dist.values,
                names=risk_dist.index,
                title="PhÃ¢n bá»‘ má»©c Ä‘á»™ rá»§i ro"
            )
            st.plotly_chart(fig_risk_dist, use_container_width=True)
        
        with col2:
            # Intervention success distribution
            fig_intervention = px.histogram(
                test_data,
                x='intervention_success',
                title="PhÃ¢n bá»‘ kháº£ nÄƒng can thiá»‡p thÃ nh cÃ´ng",
                nbins=20
            )
            st.plotly_chart(fig_intervention, use_container_width=True)
        
        # Feature importance analysis
        st.subheader("ğŸ“ˆ Táº§m quan trá»ng cá»§a cÃ¡c Ä‘áº·c trÆ°ng")
        
        if hasattr(ai_engine.risk_classifier, 'feature_importances_'):
            feature_names = [
                'Tuá»•i', 'Giá» ngá»§', 'Táº­p thá»ƒ dá»¥c', 'Há»— trá»£ xÃ£ há»™i',
                'CÄƒng tháº³ng', 'ÄÃ¡nh giÃ¡ trÆ°á»›c', 'NgÃ y tá»« láº§n cuá»‘i',
                'DASS Tráº§m cáº£m', 'DASS Lo Ã¢u', 'DASS CÄƒng tháº³ng',
                'PHQ-9', 'GAD-7', 'Giá»›i tÃ­nh', 'Há»c váº¥n'
            ]
            
            importances = ai_engine.risk_classifier.feature_importances_
            
            # Pad or trim feature_names to match importances length
            if len(feature_names) > len(importances):
                feature_names = feature_names[:len(importances)]
            elif len(feature_names) < len(importances):
                feature_names.extend([f'Feature_{i}' for i in range(len(feature_names), len(importances))])
            
            fig_importance = px.bar(
                x=importances,
                y=feature_names,
                orientation='h',
                title="Táº§m quan trá»ng cÃ¡c Ä‘áº·c trÆ°ng trong dá»± Ä‘oÃ¡n rá»§i ro"
            )
            fig_importance.update_layout(height=500)
            st.plotly_chart(fig_importance, use_container_width=True)
        
        # Model comparison
        st.subheader("ğŸ”„ So sÃ¡nh mÃ´ hÃ¬nh")
        
        models_comparison = pd.DataFrame({
            'MÃ´ hÃ¬nh': ['Random Forest', 'Gradient Boosting', 'Logistic Regression'],
            'Äá»™ chÃ­nh xÃ¡c': [0.857, 0.843, 0.789],
            'Thá»i gian huáº¥n luyá»‡n (s)': [12.3, 8.7, 2.1],
            'KÃ­ch thÆ°á»›c mÃ´ hÃ¬nh (MB)': [45.2, 32.1, 0.8]
        })
        
        st.dataframe(models_comparison, use_container_width=True)
    
    with tab4:
        st.header("ğŸ’¡ Há»‡ thá»‘ng khuyáº¿n nghá»‹ thÃ´ng minh")
        
        st.subheader("ğŸ¯ Khuyáº¿n nghá»‹ theo má»©c Ä‘á»™ rá»§i ro")
        
        # Risk-based recommendations showcase
        risk_recommendations = {
            "Low": [
                "âœ… Duy trÃ¬ lá»‘i sá»‘ng lÃ nh máº¡nh hiá»‡n táº¡i",
                "ğŸ“… ÄÃ¡nh giÃ¡ Ä‘á»‹nh ká»³ 3-6 thÃ¡ng",
                "ğŸ¯ Táº­p trung vÃ o phÃ²ng ngá»«a"
            ],
            "Moderate": [
                "ğŸ“š Há»c ká»¹ thuáº­t quáº£n lÃ½ cÄƒng tháº³ng",
                "ğŸ§˜ Thá»±c hÃ nh mindfulness hÃ ng ngÃ y",
                "ğŸ‘¥ TÄƒng cÆ°á»ng hoáº¡t Ä‘á»™ng xÃ£ há»™i",
                "ğŸ“Š Theo dÃµi tÃ¢m tráº¡ng hÃ ng tuáº§n"
            ],
            "High": [
                "âš ï¸ TÃ¬m kiáº¿m há»— trá»£ chuyÃªn nghiá»‡p trong 1-2 tuáº§n",
                "ğŸ—£ï¸ Tham gia liá»‡u phÃ¡p tÃ¢m lÃ½",
                "ğŸ“ LiÃªn há»‡ Ä‘Æ°á»ng dÃ¢y há»— trá»£",
                "ğŸ‘¨â€âš•ï¸ TÆ° váº¥n vá»›i bÃ¡c sÄ© gia Ä‘Ã¬nh"
            ],
            "Very High": [
                "ğŸš¨ Cáº§n há»— trá»£ chuyÃªn nghiá»‡p ngay láº­p tá»©c",
                "ğŸ“ Gá»i hotline kháº©n cáº¥p: 1900-xxx-xxx",
                "ğŸ¥ Äáº¿n cÆ¡ sá»Ÿ y táº¿ trong 24h",
                "ğŸ‘¥ ThÃ´ng bÃ¡o cho ngÆ°á»i thÃ¢n tin cáº­y"
            ]
        }
        
        for risk_level, recommendations in risk_recommendations.items():
            with st.expander(f"Má»©c Ä‘á»™ rá»§i ro: {risk_level}"):
                for rec in recommendations:
                    st.write(f"â€¢ {rec}")
        
        # Personalized intervention suggestions
        st.subheader("ğŸ¯ Can thiá»‡p cÃ¡ nhÃ¢n hÃ³a")
        
        intervention_types = {
            "Liá»‡u phÃ¡p tÃ¢m lÃ½": {
                "CBT": "Liá»‡u phÃ¡p nháº­n thá»©c hÃ nh vi",
                "DBT": "Liá»‡u phÃ¡p hÃ nh vi biá»‡n chá»©ng", 
                "ACT": "Liá»‡u phÃ¡p cháº¥p nháº­n vÃ  cam káº¿t"
            },
            "Thay Ä‘á»•i lá»‘i sá»‘ng": {
                "Exercise": "ChÆ°Æ¡ng trÃ¬nh táº­p thá»ƒ dá»¥c",
                "Sleep": "Cáº£i thiá»‡n vá»‡ sinh giáº¥c ngá»§",
                "Nutrition": "Cháº¿ Ä‘á»™ dinh dÆ°á»¡ng"
            },
            "Há»— trá»£ xÃ£ há»™i": {
                "Support Groups": "NhÃ³m há»— trá»£",
                "Family Therapy": "Liá»‡u phÃ¡p gia Ä‘Ã¬nh",
                "Peer Support": "Há»— trá»£ Ä‘á»“ng Ä‘áº³ng"
            }
        }
        
        for category, interventions in intervention_types.items():
            with st.expander(f"ğŸ“‹ {category}"):
                for code, description in interventions.items():
                    st.write(f"â€¢ **{code}**: {description}")
        
        # AI-powered resource matching
        st.subheader("ğŸ” TÃ¬m kiáº¿m tÃ i nguyÃªn thÃ´ng minh")
        
        location = st.selectbox(
            "Khu vá»±c cá»§a báº¡n:",
            ["HÃ  Ná»™i", "TP.HCM", "ÄÃ  Náºµng", "Cáº§n ThÆ¡", "KhÃ¡c"]
        )
        
        resource_type = st.selectbox(
            "Loáº¡i tÃ i nguyÃªn cáº§n tÃ¬m:",
            ["BÃ¡c sÄ© tÃ¢m tháº§n", "TÃ¢m lÃ½ trá»‹ liá»‡u", "NhÃ³m há»— trá»£", "Trung tÃ¢m tÆ° váº¥n"]
        )
        
        if st.button("ğŸ” TÃ¬m kiáº¿m tÃ i nguyÃªn"):
            st.success("ğŸ¯ ÄÃ£ tÃ¬m tháº¥y cÃ¡c tÃ i nguyÃªn phÃ¹ há»£p!")
            
            # Sample resources (in real app, would query database)
            sample_resources = [
                {
                    "name": "Trung tÃ¢m TÃ¢m lÃ½ ABC",
                    "address": f"{location} - Quáº­n 1",
                    "phone": "028-xxxx-xxxx",
                    "speciality": resource_type,
                    "rating": 4.8
                },
                {
                    "name": "PhÃ²ng khÃ¡m Dr. XYZ",
                    "address": f"{location} - Quáº­n 3", 
                    "phone": "028-yyyy-yyyy",
                    "speciality": resource_type,
                    "rating": 4.6
                }
            ]
            
            for resource in sample_resources:
                with st.container():
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"**{resource['name']}**")
                        st.write(f"ğŸ“ {resource['address']}")
                        st.write(f"ğŸ“ {resource['phone']}")
                        st.write(f"â­ {resource['rating']}/5.0")
                    with col2:
                        if st.button("ğŸ“ LiÃªn há»‡", key=f"contact_{resource['name']}"):
                            st.success("ÄÃ£ sao chÃ©p thÃ´ng tin liÃªn há»‡!")

# Main AI interface
def ai_main():
    ai_insights_dashboard()

if __name__ == "__main__":
    ai_main()
