"""
üé§ SOULFRIEND V4.0 - Voice Chat with CHUN
=========================================

Voice-enabled chatbot v·ªõi Speech-to-Text v√† Text-to-Speech
T√≠ch h·ª£p emotion recognition v√† real-time mood detection
"""

import streamlit as st
import speech_recognition as sr
import pyttsx3
import threading
import queue
import time
import io
import numpy as np
from typing import Optional, Dict, Any
import logging
from datetime import datetime

# Import CHUN AI system
from components.gemini_ai import GeminiAI
from components.logger import setup_logger

class VoiceChatManager:
    """
    Qu·∫£n l√Ω voice chat v·ªõi CHUN AI
    """
    
    def __init__(self):
        self.logger = setup_logger("voice_chat")
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.tts_engine = self._initialize_tts()
        self.chun_ai = GeminiAI()
        self.is_listening = False
        self.audio_queue = queue.Queue()
        
        # Voice settings
        self.speech_rate = 150  # Words per minute
        self.speech_volume = 0.8
        self.language = 'vi-VN'  # Vietnamese
        
        # Emotion detection settings
        self.emotion_keywords = {
            'happy': ['vui', 'h·∫°nh ph√∫c', 't·ªët', 'tuy·ªát v·ªùi', 'th√≠ch'],
            'sad': ['bu·ªìn', 'kh√≥c', 't·ªá', 't·ªìi t·ªá', 'ch√°n'],
            'angry': ['t·ª©c', 'gi·∫≠n', 'b·ª±c', 'ph√°t ƒëi√™n', 'c√°u'],
            'anxious': ['lo l·∫Øng', 'cƒÉng th·∫≥ng', 's·ª£', 'h·ªìi h·ªôp', 'b·ªëi r·ªëi'],
            'excited': ['h·ª©ng th√∫', 'ph·∫•n kh√≠ch', 'h√°o h·ª©c', 'mong ƒë·ª£i']
        }
        
    def _initialize_tts(self) -> Optional[pyttsx3.Engine]:
        """Initialize Text-to-Speech engine"""
        try:
            engine = pyttsx3.init()
            
            # Set Vietnamese voice if available
            voices = engine.getProperty('voices')
            for voice in voices:
                if 'vietnam' in voice.name.lower() or 'vi' in voice.id.lower():
                    engine.setProperty('voice', voice.id)
                    break
            
            engine.setProperty('rate', self.speech_rate)
            engine.setProperty('volume', self.speech_volume)
            
            return engine
        except Exception as e:
            self.logger.error(f"TTS initialization failed: {e}")
            return None
    
    def detect_emotion_from_text(self, text: str) -> str:
        """
        Detect emotion from text using keyword matching
        """
        text_lower = text.lower()
        emotion_scores = {}
        
        for emotion, keywords in self.emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                emotion_scores[emotion] = score
        
        if emotion_scores:
            detected_emotion = max(emotion_scores, key=emotion_scores.get)
            confidence = emotion_scores[detected_emotion] / len(text_lower.split())
            return f"{detected_emotion} (confidence: {confidence:.2f})"
        
        return "neutral"
    
    def speech_to_text(self, audio_data) -> Optional[str]:
        """
        Convert speech to text using Google Speech Recognition
        """
        try:
            # Use Google's speech recognition
            text = self.recognizer.recognize_google(
                audio_data, 
                language=self.language
            )
            self.logger.info(f"Speech recognized: {text}")
            return text
            
        except sr.UnknownValueError:
            self.logger.warning("Could not understand audio")
            return None
        except sr.RequestError as e:
            self.logger.error(f"Speech recognition error: {e}")
            return None
    
    def text_to_speech(self, text: str):
        """
        Convert text to speech
        """
        if not self.tts_engine:
            st.error("üîá Text-to-Speech kh√¥ng kh·∫£ d·ª•ng")
            return
        
        try:
            # Remove markdown formatting for TTS
            clean_text = text.replace('**', '').replace('*', '').replace('_', '')
            
            self.tts_engine.say(clean_text)
            self.tts_engine.runAndWait()
            
        except Exception as e:
            self.logger.error(f"TTS error: {e}")
            st.error(f"L·ªói Text-to-Speech: {e}")
    
    def listen_for_speech(self, duration: int = 5) -> Optional[str]:
        """
        Listen for speech input
        """
        try:
            with self.microphone as source:
                st.info(f"üé§ ƒêang nghe... (trong {duration} gi√¢y)")
                
                # Adjust for ambient noise
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
                
                # Listen for audio with timeout
                audio = self.recognizer.listen(source, timeout=duration, phrase_time_limit=duration)
                
                st.info("üîÑ ƒêang x·ª≠ l√Ω gi·ªçng n√≥i...")
                
                # Convert to text
                text = self.speech_to_text(audio)
                return text
                
        except sr.WaitTimeoutError:
            st.warning("‚è±Ô∏è H·∫øt th·ªùi gian nghe. Vui l√≤ng th·ª≠ l·∫°i.")
            return None
        except Exception as e:
            self.logger.error(f"Speech listening error: {e}")
            st.error(f"L·ªói khi nghe gi·ªçng n√≥i: {e}")
            return None

def create_voice_chat_interface():
    """
    Create the voice chat interface
    """
    st.title("üé§ Voice Chat v·ªõi CHUN")
    st.markdown("---")
    
    # Initialize voice chat manager
    if 'voice_manager' not in st.session_state:
        st.session_state.voice_manager = VoiceChatManager()
    
    voice_manager = st.session_state.voice_manager
    
    # Voice chat settings
    with st.expander("‚öôÔ∏è C√†i ƒë·∫∑t Voice Chat"):
        col1, col2 = st.columns(2)
        
        with col1:
            speech_rate = st.slider(
                "T·ªëc ƒë·ªô n√≥i (words/min)", 
                min_value=100, 
                max_value=300, 
                value=voice_manager.speech_rate
            )
            voice_manager.speech_rate = speech_rate
            
        with col2:
            speech_volume = st.slider(
                "√Çm l∆∞·ª£ng", 
                min_value=0.1, 
                max_value=1.0, 
                value=voice_manager.speech_volume
            )
            voice_manager.speech_volume = speech_volume
        
        if voice_manager.tts_engine:
            voice_manager.tts_engine.setProperty('rate', speech_rate)
            voice_manager.tts_engine.setProperty('volume', speech_volume)
    
    # Chat history
    if 'voice_chat_history' not in st.session_state:
        st.session_state.voice_chat_history = []
    
    # Display chat history
    st.subheader("üí¨ Cu·ªôc tr√≤ chuy·ªán")
    
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.voice_chat_history:
            if message['role'] == 'user':
                with st.chat_message("user"):
                    st.write(f"üé§ **B·∫°n**: {message['content']}")
                    if 'emotion' in message:
                        st.caption(f"üòä C·∫£m x√∫c: {message['emotion']}")
            else:
                with st.chat_message("assistant"):
                    st.write(f"ü§ñ **CHUN**: {message['content']}")
    
    # Voice input controls
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üé§ B·∫Øt ƒë·∫ßu n√≥i", key="start_voice"):
            with st.spinner("ƒêang nghe..."):
                user_speech = voice_manager.listen_for_speech(duration=10)
                
                if user_speech:
                    st.success(f"‚úÖ ƒê√£ nghe: {user_speech}")
                    
                    # Detect emotion
                    emotion = voice_manager.detect_emotion_from_text(user_speech)
                    
                    # Add to chat history
                    st.session_state.voice_chat_history.append({
                        'role': 'user',
                        'content': user_speech,
                        'emotion': emotion,
                        'timestamp': datetime.now()
                    })
                    
                    # Get CHUN response
                    with st.spinner("CHUN ƒëang suy nghƒ©..."):
                        # Enhanced prompt with emotion context
                        enhanced_prompt = f"""
                        Tin nh·∫Øn: {user_speech}
                        C·∫£m x√∫c ph√°t hi·ªán: {emotion}
                        
                        H√£y tr·∫£ l·ªùi nh∆∞ CHUN v·ªõi t√≠nh c√°ch ƒë·ªìng c·∫£m, 
                        ƒë·∫∑c bi·ªát ch√∫ √Ω ƒë·∫øn c·∫£m x√∫c ƒë∆∞·ª£c ph√°t hi·ªán.
                        """
                        
                        chun_response = voice_manager.chun_ai.get_response(enhanced_prompt)
                        
                        if chun_response:
                            # Add CHUN response to history
                            st.session_state.voice_chat_history.append({
                                'role': 'assistant',
                                'content': chun_response,
                                'timestamp': datetime.now()
                            })
                            
                            st.success("‚úÖ CHUN ƒë√£ tr·∫£ l·ªùi!")
                            st.rerun()
                        else:
                            st.error("‚ùå CHUN kh√¥ng th·ªÉ tr·∫£ l·ªùi l√∫c n√†y")
                else:
                    st.warning("‚ùå Kh√¥ng nghe ƒë∆∞·ª£c gi·ªçng n√≥i")
    
    with col2:
        if st.button("üîä ƒê·ªçc tin nh·∫Øn cu·ªëi", key="read_last"):
            if st.session_state.voice_chat_history:
                last_message = st.session_state.voice_chat_history[-1]
                if last_message['role'] == 'assistant':
                    with st.spinner("ƒêang ƒë·ªçc..."):
                        voice_manager.text_to_speech(last_message['content'])
                    st.success("‚úÖ ƒê√£ ƒë·ªçc xong!")
                else:
                    st.info("Tin nh·∫Øn cu·ªëi kh√¥ng ph·∫£i t·ª´ CHUN")
            else:
                st.warning("Ch∆∞a c√≥ tin nh·∫Øn n√†o")
    
    with col3:
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠", key="clear_voice_history"):
            st.session_state.voice_chat_history = []
            st.success("‚úÖ ƒê√£ x√≥a l·ªãch s·ª≠ chat")
            st.rerun()
    
    # Text input fallback
    st.markdown("---")
    st.subheader("‚å®Ô∏è Ho·∫∑c g√µ tin nh·∫Øn")
    
    text_input = st.text_input(
        "Nh·∫≠p tin nh·∫Øn cho CHUN:",
        placeholder="G√µ tin nh·∫Øn ho·∫∑c s·ª≠ d·ª•ng voice chat ·ªü tr√™n..."
    )
    
    if st.button("üì§ G·ª≠i tin nh·∫Øn", key="send_text"):
        if text_input:
            # Detect emotion from text
            emotion = voice_manager.detect_emotion_from_text(text_input)
            
            # Add to chat history
            st.session_state.voice_chat_history.append({
                'role': 'user',
                'content': text_input,
                'emotion': emotion,
                'timestamp': datetime.now()
            })
            
            # Get CHUN response
            with st.spinner("CHUN ƒëang tr·∫£ l·ªùi..."):
                enhanced_prompt = f"""
                Tin nh·∫Øn: {text_input}
                C·∫£m x√∫c ph√°t hi·ªán: {emotion}
                
                H√£y tr·∫£ l·ªùi nh∆∞ CHUN v·ªõi t√≠nh c√°ch ƒë·ªìng c·∫£m.
                """
                
                chun_response = voice_manager.chun_ai.get_response(enhanced_prompt)
                
                if chun_response:
                    # Add CHUN response to history
                    st.session_state.voice_chat_history.append({
                        'role': 'assistant',
                        'content': chun_response,
                        'timestamp': datetime.now()
                    })
                    
                    st.rerun()
    
    # Voice chat statistics
    st.markdown("---")
    st.subheader("üìä Th·ªëng k√™ Voice Chat")
    
    if st.session_state.voice_chat_history:
        user_messages = [m for m in st.session_state.voice_chat_history if m['role'] == 'user']
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("üí¨ Tin nh·∫Øn", len(st.session_state.voice_chat_history))
        
        with col2:
            st.metric("üé§ Voice inputs", 
                     sum(1 for m in user_messages if 'emotion' in m))
        
        with col3:
            if user_messages:
                emotions = [m.get('emotion', 'neutral') for m in user_messages if 'emotion' in m]
                most_common_emotion = max(set(emotions), key=emotions.count) if emotions else 'neutral'
                st.metric("üòä C·∫£m x√∫c ch·ªß ƒë·∫°o", most_common_emotion)
    
    # Tips and instructions
    with st.expander("üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Voice Chat"):
        st.markdown("""
        ### üé§ **C√°ch s·ª≠ d·ª•ng Voice Chat:**
        
        1. **B·∫•m n√∫t "üé§ B·∫Øt ƒë·∫ßu n√≥i"**
        2. **N√≥i r√µ r√†ng** trong v√≤ng 10 gi√¢y
        3. **CHUN s·∫Ω ph√¢n t√≠ch c·∫£m x√∫c** v√† tr·∫£ l·ªùi ph√π h·ª£p
        4. **B·∫•m "üîä ƒê·ªçc tin nh·∫Øn cu·ªëi"** ƒë·ªÉ nghe CHUN n√≥i
        
        ### üîß **T√≠nh nƒÉng:**
        - ‚úÖ **Speech-to-Text**: Chuy·ªÉn gi·ªçng n√≥i th√†nh text
        - ‚úÖ **Text-to-Speech**: CHUN c√≥ th·ªÉ ƒë·ªçc ph·∫£n h·ªìi
        - ‚úÖ **Emotion Detection**: Ph√¢n t√≠ch c·∫£m x√∫c t·ª´ gi·ªçng n√≥i
        - ‚úÖ **Context Awareness**: CHUN hi·ªÉu ng·ªØ c·∫£nh c·∫£m x√∫c
        
        ### üìù **L∆∞u √Ω:**
        - C·∫ßn **microphone v√† speakers** ƒë·ªÉ s·ª≠ d·ª•ng ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng
        - **N√≥i ti·∫øng Vi·ªát** ƒë·ªÉ k·∫øt qu·∫£ t·ªët nh·∫•t
        - C√≥ th·ªÉ **k·∫øt h·ª£p voice v√† text** trong c√πng cu·ªôc tr√≤ chuy·ªán
        """)

if __name__ == "__main__":
    # Required dependencies check
    try:
        import speech_recognition
        import pyttsx3
        create_voice_chat_interface()
    except ImportError as e:
        st.error(f"""
        üö´ **Thi·∫øu dependencies cho Voice Chat**
        
        C·∫ßn c√†i ƒë·∫∑t: `{e.name}`
        
        Ch·∫°y l·ªánh:
        ```bash
        pip install speech-recognition pyttsx3 pyaudio
        ```
        """)
